{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1aef7c-30e1-4d8d-8633-cc1e34ce2595",
   "metadata": {},
   "source": [
    "# Inference demo for Cervical Cancer subclass classifier\n",
    "In this notebook, we demonstrate how to load a pre-trained Cervical Cancer Subclass Classifier and use it to predict the class of new images. The notebook will guide you through the process of loading the model, making predictions, and visualizing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f391d-0d8c-4eb1-a439-ba39fdd365bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.models.cervical_cancer_model import CervicalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa2a7a-2d8b-4a55-9e22-3c2c3c0b7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f883a-9009-486b-8378-32178b1f1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config settings\n",
    "num_classes = 5\n",
    "\n",
    "# Load model with checkpoint\n",
    "model = CervicalModel(num_classes=num_classes)\n",
    "checkpoint_path = '../results/cervical_checkpoints/best_checkpoint.pth'  # Your path\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device, weights_only=True))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc727b-63ab-4b71-ac8b-99163090bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize image\n",
    "def imshow(img):\n",
    "    \"\"\"Display an image from a tensor.\"\"\"\n",
    "    img = img / 2 + 0.5 # Undo normalization\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Image prediction\n",
    "def predict_image(model, image_path, class_names):\n",
    "    \"\"\"Predict the class of an image using the trained model.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Model is trained with 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize as in training\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    plt.imshow(image)  # Show original iamge\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.show()\n",
    "\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    image = image.to(device)\n",
    "    outputs = model(image)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6198c-8d64-4287-9b70-7505b4202a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Path to test dataset\n",
    "test_images_path = 'D:/Data/cervical_cancer_data/test/'\n",
    "\n",
    "# Get random image\n",
    "category = random.choice(os.listdir(test_images_path))\n",
    "image_path = os.path.join(test_images_path, category, random.choice(os.listdir(os.path.join(test_images_path, category))))\n",
    "print(f\"Selected Image: {image_path}\")\n",
    "\n",
    "# Class names list\n",
    "class_names = os.listdir(test_images_path)\n",
    "\n",
    "# Do prediction\n",
    "predicted_class = predict_image(model, image_path, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4b5d1-f307-4daa-95c8-bd7e0da9dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show multiple images with their predictions\n",
    "def visualize_predictions(model, test_images_path, class_names, num_images=5):\n",
    "    \"\"\"Visualize predictions for multiple random images from the test set.\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(num_images):\n",
    "        category = random.choice(os.listdir(test_images_path))\n",
    "        image_path = os.path.join(test_images_path, category, random.choice(os.listdir(os.path.join(test_images_path, category))))\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_class = class_names[predicted.item()]\n",
    "        \n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Predicted: {predicted_class}\", color=\"green\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Show 5 predictions\n",
    "visualize_predictions(model, test_images_path, class_names, num_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62e1af-3311-414e-849b-128f7e8df222",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this notebook, we have demonstrated how to load a pre-trained Cervical Cancer Subclass Classifier, predict the subclass of new images, and visualize the model's predictions. This notebook provides an intuitive way to test the performance of the model on unseen data. For a more detailed evaluation, refer to the training and test reports in the `results/` folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

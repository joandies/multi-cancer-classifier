{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d258eb0a-c1c9-48a6-be0a-caf1b318a1f3",
   "metadata": {},
   "source": [
    "# Test Cervical Cancer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd6eddb-3419-48d6-8115-f0a84aca0d1b",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cec5e0-6c57-4dcd-a8a6-f570089e6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.models.cervical_cancer_model import CervicalModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d37fd2f-ec50-415a-aa07-4977f2ec5ab8",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c62fde-6835-4d19-bf17-5a5486f2e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CervicalModel(num_classes=5)  # Adjust num_classes based on your configuration\n",
    "checkpoint_path = '../results/cervical_checkpoints/best_checkpoint.pth' # Checkpoint path\n",
    "\n",
    "# Load the model's state dict (weights)\n",
    "model.load_state_dict(torch.load(checkpoint_path, weights_only=True))\n",
    "_ = model.to(device)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a1428-6190-48ae-865c-11e1d0ba620a",
   "metadata": {},
   "source": [
    "### Define the image transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089317b9-5f01-44ec-8dd8-a613f1bb37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),  # Resize to a fixed size\n",
    "    transforms.CenterCrop(224),  # Crop to 224x224 to match the model input\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize like ImageNet\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa00375-a6fa-40ad-9223-e2dbc5b50b5f",
   "metadata": {},
   "source": [
    "### Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b09a3a-10e7-43d9-aec0-96ad9366ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = 'D:/Data/cervical_cancer_data/test'\n",
    "test_dataset = datasets.ImageFolder(root=test_dataset_path, transform=transform)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1685433b-33dd-4b45-9c64-c0e1be28bc61",
   "metadata": {},
   "source": [
    "### Function to display image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b65be-8ed5-4459-86ff-1a1e3ccba84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c922c-87e9-4376-898e-926fc2355e6d",
   "metadata": {},
   "source": [
    "### Make predictions on a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a57da-ae68-4797-b66b-ae19aabbb4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a test image\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Display the first image\n",
    "imshow(images[0])\n",
    "\n",
    "# Move image and labels to the device (GPU or CPU)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# Get the model's prediction\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Get the true label\n",
    "true_label = labels.item()\n",
    "\n",
    "# Print predicted class label\n",
    "class_names = test_dataset.classes\n",
    "predicted_class = class_names[predicted]\n",
    "\n",
    "# Print whether the prediction is correct\n",
    "print(f'Predicted: {predicted_class}')\n",
    "print(f'True Label: {class_names[true_label]}')\n",
    "\n",
    "if predicted == labels:\n",
    "    print(\"Prediction is correct.\")\n",
    "else:\n",
    "    print(\"Prediction is incorrect.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
